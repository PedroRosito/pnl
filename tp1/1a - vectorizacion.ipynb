{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"data":{"text/plain":["array(['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas',\n","       'que'], dtype='<U7')"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["def corpus_words(corpus):\n","    split_corpus = np.char.split(corpus)\n","    corpus_words = np.concatenate(split_corpus)\n","    unique_terms = np.unique(corpus_words)\n","    return unique_terms\n","\n","corpus_words(corpus)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def corpus_one_hot(corpus):    \n","    words, indexes = np.unique(np.unique(corpus_words(corpus)), return_inverse=True)\n","    one_hot = np.zeros((indexes.size, indexes.max() + 1))\n","    one_hot[np.arange(indexes.size), indexes] = 1\n","    return words, one_hot"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[{"data":{"text/plain":["[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n","  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n","  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n","  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]],\n"," [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n","  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n","  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n","  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n","  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n","  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n","  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]],\n"," [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n","  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n","  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","\n","def one_hot_encoding(corpus):\n","    split_corpus = np.char.split(corpus)\n","    words, one_hot = corpus_one_hot(corpus)\n","    texts_encoded = []\n","    for text in split_corpus:\n","        split_text = np.char.split(text)\n","        text_encoded = []\n","        for word in split_text:\n","            index = np.where(words == word)\n","            text_encoded.append(one_hot[index][0].tolist())\n","        texts_encoded.append(text_encoded)\n","    return texts_encoded\n","\n","one_hot_encoding(corpus)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[{"data":{"text/plain":["[[0, 1, 0, 1, 0, 1, 0, 0, 1],\n"," [1, 1, 1, 1, 0, 1, 2, 0, 0],\n"," [0, 0, 0, 0, 1, 0, 1, 1, 0]]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","\n","def freq_vector(corpus):\n","    split_corpus = np.char.split(corpus)\n","    words, one_hot = corpus_one_hot(corpus)\n","    freq_array = []\n","    for text in split_corpus:\n","        split_text = np.char.split(text)\n","        text_encoded = []\n","        for word in split_text:\n","            index = np.where(words == word)\n","            text_encoded.append(one_hot[index][0].tolist())\n","        freq_array.append(np.sum(text_encoded, axis=0).astype(int).tolist())\n","    return freq_array\n","\n","freq_vector(corpus)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[{"data":{"text/plain":["array([[0.        , 0.17609126, 0.        , 0.17609126, 0.        ,\n","        0.17609126, 0.        , 0.        , 0.47712125],\n","       [0.47712125, 0.17609126, 0.47712125, 0.17609126, 0.        ,\n","        0.17609126, 0.35218252, 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.47712125,\n","        0.        , 0.17609126, 0.47712125, 0.        ]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","\n","def tf_idf(corpus):\n","    split_corpus = np.char.split(corpus)\n","    num_docs = len(split_corpus)\n","\n","    freq_array = []\n","    for text_encoded in one_hot_encoding(corpus):\n","        freq_array.append(np.any(text_encoded, axis=0).astype(int))\n","\n","    idf = np.log10(np.divide(num_docs, np.sum(freq_array, axis=0).astype(int)))\n","\n","    return freq_vector(corpus) * idf\n","\n","tf_idf(corpus)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['que', 'dia', 'es', 'hoy'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['martes', 'muchas', 'gracias']]\n","[['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['que', 'dia', 'es', 'hoy'], ['martes', 'muchas', 'gracias']]\n","[['martes', 'muchas', 'gracias'], ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'], ['que', 'dia', 'es', 'hoy']]\n"]}],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])\n","\n","def cosine_similarity_cmp(corpus, index):\n","    split_corpus = np.char.split(corpus)\n","\n","    result = []\n","    try:\n","        split_corpus[index]\n","    except Exception:\n","        return 'El índice está fuera de rango'\n","\n","    TF_IDF = tf_idf(corpus)\n","\n","    for i, vector in enumerate(TF_IDF):\n","        result.append((i, cosine_similarity(TF_IDF[index], vector)))\n","\n","    result.sort(key=lambda x: x[1], reverse=True)\n","    ordered_docs = [split_corpus[i] for i, _ in result]\n","    print(ordered_docs)\n","\n","for i in range(3):\n","    cosine_similarity_cmp(corpus, i)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":0}
